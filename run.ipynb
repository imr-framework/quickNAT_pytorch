{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a08ba24a0225>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0meu\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mquicknat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQuickNat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msettings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSettings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_imdb_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Columbia\\GitHub Clone\\quickNAT_pytorch\\utils\\evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon_utils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcommon_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdu\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Columbia\\GitHub Clone\\quickNAT_pytorch\\utils\\data_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qiane\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# We tried working around this by using \"package_dir\" but that breaks Cython.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import utils.evaluator as eu\n",
    "from quicknat import QuickNat\n",
    "from settings import Settings\n",
    "from solver import Solver\n",
    "from utils.data_utils import get_imdb_dataset\n",
    "from utils.log_utils import LogWriter\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_params):\n",
    "    print(\"Loading dataset\")\n",
    "    train_data, test_data = get_imdb_dataset(data_params)\n",
    "    print(\"Train size: %i\" % len(train_data))\n",
    "    print(\"Test size: %i\" % len(test_data))\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_params, common_params, data_params, net_params):\n",
    "    train_data, test_data = load_data(data_params)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=train_params['train_batch_size'], shuffle=True,\n",
    "                                               num_workers=4, pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(test_data, batch_size=train_params['val_batch_size'], shuffle=False,\n",
    "                                             num_workers=4, pin_memory=True)\n",
    "\n",
    "    if train_params['use_pre_trained']:\n",
    "        quicknat_model = torch.load(train_params['pre_trained_path'])\n",
    "    else:\n",
    "        quicknat_model = QuickNat(net_params)\n",
    "\n",
    "    solver = Solver(quicknat_model,\n",
    "                    device=common_params['device'],\n",
    "                    num_class=net_params['num_class'],\n",
    "                    optim_args={\"lr\": train_params['learning_rate'],\n",
    "                                \"betas\": train_params['optim_betas'],\n",
    "                                \"eps\": train_params['optim_eps'],\n",
    "                                \"weight_decay\": train_params['optim_weight_decay']},\n",
    "                    model_name=common_params['model_name'],\n",
    "                    exp_name=train_params['exp_name'],\n",
    "                    labels=data_params['labels'],\n",
    "                    log_nth=train_params['log_nth'],\n",
    "                    num_epochs=train_params['num_epochs'],\n",
    "                    lr_scheduler_step_size=train_params['lr_scheduler_step_size'],\n",
    "                    lr_scheduler_gamma=train_params['lr_scheduler_gamma'],\n",
    "                    use_last_checkpoint=train_params['use_last_checkpoint'],\n",
    "                    log_dir=common_params['log_dir'],\n",
    "                    exp_dir=common_params['exp_dir'])\n",
    "\n",
    "    solver.train(train_loader, val_loader)\n",
    "    final_model_path = os.path.join(common_params['save_model_dir'], train_params['final_model_file'])\n",
    "    quicknat_model.save(final_model_path)\n",
    "    print(\"final model saved @ \" + str(final_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_params, net_params, data_params, common_params, train_params):\n",
    "    eval_model_path = eval_params['eval_model_path']\n",
    "    num_classes = net_params['num_class']\n",
    "    labels = data_params['labels']\n",
    "    data_dir = eval_params['data_dir']\n",
    "    label_dir = eval_params['label_dir']\n",
    "    volumes_txt_file = eval_params['volumes_txt_file']\n",
    "    remap_config = eval_params['remap_config']\n",
    "    device = common_params['device']\n",
    "    log_dir = common_params['log_dir']\n",
    "    exp_dir = common_params['exp_dir']\n",
    "    exp_name = train_params['exp_name']\n",
    "    save_predictions_dir = eval_params['save_predictions_dir']\n",
    "    prediction_path = os.path.join(exp_dir, exp_name, save_predictions_dir)\n",
    "    orientation = eval_params['orientation']\n",
    "\n",
    "    logWriter = LogWriter(num_classes, log_dir, exp_name, labels=labels)\n",
    "\n",
    "    avg_dice_score, class_dist = eu.evaluate_dice_score(eval_model_path,\n",
    "                                                        num_classes,\n",
    "                                                        data_dir,\n",
    "                                                        label_dir,\n",
    "                                                        volumes_txt_file,\n",
    "                                                        remap_config,\n",
    "                                                        orientation,\n",
    "                                                        prediction_path,\n",
    "                                                        device,\n",
    "                                                        logWriter)\n",
    "    logWriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_contents(folder):\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--mode', '-m', required=True, help='run mode, valid values are train and eval')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    settings = Settings()\n",
    "    common_params, data_params, net_params, train_params, eval_params = settings['COMMON'], settings['DATA'], settings[\n",
    "        'NETWORK'], settings['TRAINING'], settings['EVAL']\n",
    "\n",
    "    if args.mode == 'train':\n",
    "        train(train_params, common_params, data_params, net_params)\n",
    "    elif args.mode == 'eval':\n",
    "        evaluate(eval_params, net_params, data_params, common_params, train_params)\n",
    "    elif args.mode == 'clear':\n",
    "        shutil.rmtree(os.path.join(common_params['exp_dir'], train_params['exp_name']))\n",
    "        print(\"Cleared current experiment directory successfully!!\")\n",
    "        shutil.rmtree(os.path.join(common_params['log_dir'], train_params['exp_name']))\n",
    "        print(\"Cleared current log directory successfully!!\")\n",
    "\n",
    "    elif args.mode == 'clear-all':\n",
    "        delete_contents(common_params['exp_dir'])\n",
    "        print(\"Cleared experiments directory successfully!!\")\n",
    "        delete_contents(common_params['log_dir'])\n",
    "        print(\"Cleared logs directory successfully!!\")\n",
    "    else:\n",
    "        raise ValueError('Invalid value for mode. only support values are train, eval and clear')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:light",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
